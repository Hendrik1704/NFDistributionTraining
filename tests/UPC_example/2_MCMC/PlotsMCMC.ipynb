{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run MCMC for JIMWLK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import workdir, parse_model_parameter_file\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import entropy\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the path three levels up and add it to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..')))\n",
    "\n",
    "from src.realnvp.utils import load\n",
    "\n",
    "plt.rcParams.update({'font.size': 24})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_labels = [\n",
    "    r\"$m\\;[\\mathrm{GeV}]$\", \n",
    "    r\"$B_G\\;[\\mathrm{GeV}^{-2}]$\", \n",
    "    r\"$B_{q}\\;[\\mathrm{GeV}^{-2}]$\", \n",
    "    r\"$\\sigma$\", \n",
    "    r\"$Q_s/(g^2\\mu)$\", \n",
    "    r\"$m_{\\mathrm{JIMWLK}}\\;[\\mathrm{GeV}]$\", \n",
    "    r\"$\\Lambda_{\\mathrm{QCD}}\\;[\\mathrm{GeV}]$\"\n",
    "]\n",
    "\n",
    "bounds = np.array([[0.02, 1.2],  # m\n",
    "                [1, 10],    # BG\n",
    "                [0.05, 3],  # BGq\n",
    "                [0, 1.5],   # smearQsWidth\n",
    "                [0.05, 1.50], # QsmuRatio\n",
    "                [0.02, 1.2], # m_jimwlk\n",
    "                [0.0001, 0.28] # Lambda_QCD_jimwlk\n",
    "                ])\n",
    "\n",
    "def read_pkl_file_chain_pocoMC(PATH_pklfile_chains):\n",
    "    \"\"\"\n",
    "    data is a dictionary containing:\n",
    "    - 'chain'\n",
    "    - 'weights'\n",
    "    - 'logl'\n",
    "    - 'logp'\n",
    "    - 'logz'\n",
    "    - 'logz_err'\n",
    "    \"\"\"\n",
    "    with open(PATH_pklfile_chains, 'rb') as pf:\n",
    "        data = pickle.load(pf)\n",
    "\n",
    "    # delete columns \n",
    "    data['chain'] = np.delete(data['chain'], [3, 8, 9, 10], axis=1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_1d_kl(p_samples, q_samples, bounds, bins=100, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Computes the KL divergence for each 1D marginal (diagonal of corner plot).\n",
    "    Arguments:\n",
    "        p_samples, q_samples: Arrays of shape (n_samples, n_dims)\n",
    "        bounds: np.ndarray of shape (n_dims, 2) specifying min and max for each dimension\n",
    "    Returns:\n",
    "        kls: List of KL divergences for each dimension\n",
    "        mean_kl: Mean KL divergence across all dimensions\n",
    "    \"\"\"\n",
    "    kls = []\n",
    "    dim = p_samples.shape[1]\n",
    "    for i in range(dim):\n",
    "        range_i = bounds[i]\n",
    "        p_hist, bin_edges = np.histogram(p_samples[:, i], bins=bins, range=range_i, density=True)\n",
    "        q_hist, _ = np.histogram(q_samples[:, i], bins=bin_edges, density=True)\n",
    "\n",
    "        # Avoid log(0)\n",
    "        p_hist += epsilon\n",
    "        q_hist += epsilon\n",
    "\n",
    "        kl = entropy(p_hist, q_hist)\n",
    "        kls.append(kl)\n",
    "    return kls, np.mean(kls)\n",
    "\n",
    "\n",
    "def compute_2d_kl_lower(p_samples, q_samples, bounds, bins=40, epsilon=1e-10):\n",
    "    \"\"\"\n",
    "    Computes KL divergence for each 2D correlation (lower triangle of corner plot).\n",
    "    Arguments:\n",
    "        p_samples, q_samples: Arrays of shape (n_samples, n_dims)\n",
    "        bounds: np.ndarray of shape (n_dims, 2) specifying min and max for each dimension\n",
    "    Returns:\n",
    "        kls_2d: List of tuples ((i, j), kl) for each lower-triangle pair\n",
    "        avg_kl_2d: Mean KL divergence across all pairs\n",
    "    \"\"\"\n",
    "    kls_2d = []\n",
    "    dim = p_samples.shape[1]\n",
    "    for i in range(dim):\n",
    "        for j in range(i):\n",
    "            range_2d = [bounds[i], bounds[j]]\n",
    "            p_hist, xedges, yedges = np.histogram2d(\n",
    "                p_samples[:, i], p_samples[:, j], bins=bins, range=range_2d, density=True\n",
    "            )\n",
    "            q_hist, _, _ = np.histogram2d(\n",
    "                q_samples[:, i], q_samples[:, j], bins=[xedges, yedges], density=True\n",
    "            )\n",
    "\n",
    "            # Flatten and regularize\n",
    "            p_flat = p_hist.flatten() + epsilon\n",
    "            q_flat = q_hist.flatten() + epsilon\n",
    "\n",
    "            kl_2d = entropy(p_flat, q_flat)\n",
    "            kls_2d.append(((i, j), kl_2d))\n",
    "    \n",
    "    avg_kl_2d = np.mean([k[1] for k in kls_2d]) if kls_2d else 0.0\n",
    "    return kls_2d, avg_kl_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NFSampler:\n",
    "    def __init__(self, path_NF_model, seed=None):\n",
    "        self.dim = 2\n",
    "        self.bounds = np.array([[0.02, 1.2],  # m\n",
    "                                [1, 10],    # BG\n",
    "                                [0.05, 3],  # BGq\n",
    "                                [0, 1.5],   # smearQsWidth\n",
    "                                [0.05, 1.50], # QsmuRatio\n",
    "                                [0.02, 1.2], # m_jimwlk\n",
    "                                [0.0001, 0.28] # Lambda_QCD_jimwlk\n",
    "                                ])\n",
    "\n",
    "        # Specify to use CPU, not GPU.\n",
    "        jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "        if seed is None:\n",
    "            seed = time.time_ns()\n",
    "        self.sample_key, self.init_key = jax.random.split(jax.random.PRNGKey(seed), 2)\n",
    "\n",
    "        # Load the normalizing flow and its hyperparameters\n",
    "        self.flow, self.hyperparams = load(path_NF_model, self.init_key)\n",
    "        self.dimension = self.hyperparams['dimension']\n",
    "\n",
    "    def _in_bounds(self, x):\n",
    "        lower = jnp.array(self.bounds[:, 0])\n",
    "        upper = jnp.array(self.bounds[:, 1])\n",
    "        return jnp.all((x >= lower) & (x <= upper), axis=1)\n",
    "\n",
    "    def sample(self, size=1):\n",
    "        accepted = []\n",
    "        while len(accepted) < size:\n",
    "            self.sample_key, pkey = jax.random.split(self.sample_key)\n",
    "            z = jax.random.normal(pkey, (size, self.dimension))\n",
    "            x, _ = self.flow(z)\n",
    "\n",
    "            mask = np.array(self._in_bounds(x))\n",
    "            x_np = np.array(x)\n",
    "            accepted.extend(x_np[mask])\n",
    "\n",
    "        return np.array(accepted[:size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_corner_comparison_plot_paper(data1, data2, NF_model_path, bounds, \n",
    "                                      labels=None, \n",
    "                                      density_labels=None,\n",
    "                                      bins=50, figsize=(12, 12),\n",
    "                                      save_path=None,\n",
    "                                      kl_1d=None, \n",
    "                                      kl_2d=None,\n",
    "                                      mean_kl=None,\n",
    "                                      title=None):\n",
    "    \"\"\"\n",
    "    Create a corner plot comparing training_data and model_samples with fixed bounds.\n",
    "    \n",
    "    Parameters:\n",
    "    - data1: (N, D) numpy array\n",
    "    - data2: (M, D) numpy array\n",
    "    - NF_model_path: path to the NF model file\n",
    "    - bounds: (D, 2) array of [min, max] for each dimension\n",
    "    - labels: list of length D with parameter names\n",
    "    - density_labels: list of length 2 with density plot labels\n",
    "    - bins: number of histogram bins\n",
    "    - figsize: figure size\n",
    "    - save_path: path to save the plot (optional)\n",
    "    - kl_1d: optional array of shape (D,) with 1D KL divergences\n",
    "    - kl_2d: optional array of shape (D, D) with 2D KL divergences\n",
    "    - mean_kl: optional mean KL divergence across all dimensions\n",
    "    - title: optional title for the plot\n",
    "    \"\"\"\n",
    "    sampler = NFSampler(NF_model_path)\n",
    "    model_samples = jax.device_get(sampler.sample(size=data1.shape[0]))\n",
    "\n",
    "    def get_contour_levels(Z, levels):\n",
    "        Z_flat = Z.flatten()\n",
    "        Z_sorted = np.sort(Z_flat)[::-1]\n",
    "        cumsum = np.cumsum(Z_sorted)\n",
    "        cumsum /= cumsum[-1]  # normalize to [0,1]\n",
    "        levels_out = [Z_sorted[np.searchsorted(cumsum, level)] for level in levels]\n",
    "        return sorted(levels_out)\n",
    "\n",
    "    D = data1.shape[1]\n",
    "    fig, axes = plt.subplots(D, D, figsize=figsize, sharex='col', sharey='row')\n",
    "\n",
    "    for i in range(D):\n",
    "        for j in range(D):\n",
    "            ax = axes[i, j]\n",
    "\n",
    "            if i == j:\n",
    "                # Diagonal: 1D histograms\n",
    "                ax = fig.add_subplot(D, D, i * D + j + 1)\n",
    "                ax.hist(data1[:, i], bins=bins, density=True, alpha=0.5,\n",
    "                        color='tab:green', label=density_labels[0], range=bounds[i])\n",
    "                ax.hist(model_samples[:, i], bins=bins, density=True,\n",
    "                        color='tab:orange', histtype='step', linewidth=2,\n",
    "                        label=density_labels[1], range=bounds[i], linestyle=':')\n",
    "                ax.hist(data2[:, i], bins=bins, density=True,\n",
    "                        color='tab:purple', histtype='step', linewidth=2,\n",
    "                        label=density_labels[2], range=bounds[i], linestyle='--')\n",
    "                ax.set_yticks([])\n",
    "                ax.set_yticklabels([])\n",
    "                if i != D-1:\n",
    "                    ax.set_xticks([])\n",
    "                    ax.set_xticklabels([])\n",
    "                if i == D-1:\n",
    "                    ax.tick_params(axis='x', rotation=45, labelsize=10)\n",
    "\n",
    "                ax.set_xlim(bounds[i])\n",
    "                ax.set_ylim(0, None)\n",
    "\n",
    "                if kl_1d is not None:\n",
    "                    ax.annotate(rf\"$D_{{KL}}={kl_1d[i]:.3f}$\", xy=(0.95, 0.95), \n",
    "                                xycoords='axes fraction',\n",
    "                                ha='right', va='top', fontsize=10)\n",
    "            elif j < i:\n",
    "                # Lower triangle: 2D histograms\n",
    "                ax.hist2d(data1[:, j], data1[:, i], bins=bins,\n",
    "                          range=[bounds[j], bounds[i]], cmap='Greens', alpha=0.5)\n",
    "\n",
    "                x = np.linspace(bounds[j][0], bounds[j][1], bins)\n",
    "                y = np.linspace(bounds[i][0], bounds[i][1], bins)\n",
    "                X, Y = np.meshgrid(x, y)\n",
    "                # Add contour for training_data (solid)\n",
    "                try:\n",
    "                    data_train = np.vstack([data1[:, j], data1[:, i]])\n",
    "                    kde_train = gaussian_kde(data_train)\n",
    "                    Z_train = kde_train(np.vstack([X.ravel(), Y.ravel()])).reshape(X.shape)\n",
    "                    contour_levels = get_contour_levels(Z_train, levels=[0.685, 0.955, 0.997])\n",
    "                    ax.contour(X, Y, Z_train, levels=contour_levels, colors='green', linewidths=1.2)\n",
    "                except Exception as e:\n",
    "                    print(f\"Contour failed for training data at ({i},{j}): {e}\")\n",
    "                \n",
    "                # Add contour for model_samples (dashed)\n",
    "                try:\n",
    "                    data_model = np.vstack([data2[:, j], data2[:, i]])\n",
    "                    kde_model = gaussian_kde(data_model)\n",
    "                    Z_model = kde_model(np.vstack([X.ravel(), Y.ravel()])).reshape(X.shape)\n",
    "                    contour_levels_model = get_contour_levels(Z_model, levels=[0.685, 0.955, 0.997])\n",
    "                    ax.contour(X, Y, Z_model, levels=contour_levels_model, colors='purple',\n",
    "                            linewidths=1.2, linestyles='dashed')\n",
    "                except Exception as e:\n",
    "                    print(f\"Contour failed for model data at ({i},{j}): {e}\")\n",
    "\n",
    "                ax.set_xlim(bounds[j])\n",
    "                ax.set_ylim(bounds[i])\n",
    "\n",
    "                if kl_2d is not None and not np.isnan(kl_2d[i, j]):\n",
    "                    ax.annotate(rf\"$D_{{KL}}={kl_2d[i, j]:.3f}$\", xy=(0.95, 0.95), \n",
    "                                xycoords='axes fraction',\n",
    "                                ha='right', va='top', fontsize=10)\n",
    "            else:\n",
    "                #ax.axis('off')\n",
    "                ax.hist2d(model_samples[:, j], model_samples[:, i], bins=bins,\n",
    "                          range=[bounds[j], bounds[i]], cmap='Oranges', alpha=0.5)\n",
    "                \n",
    "                x = np.linspace(bounds[j][0], bounds[j][1], bins)\n",
    "                y = np.linspace(bounds[i][0], bounds[i][1], bins)\n",
    "                X, Y = np.meshgrid(x, y)\n",
    "                # Add contour for training_data (solid)\n",
    "                try:\n",
    "                    data_train = np.vstack([model_samples[:, j], model_samples[:, i]])\n",
    "                    kde_train = gaussian_kde(data_train)\n",
    "                    Z_train = kde_train(np.vstack([X.ravel(), Y.ravel()])).reshape(X.shape)\n",
    "                    contour_levels = get_contour_levels(Z_train, levels=[0.685, 0.955, 0.997])\n",
    "                    ax.contour(X, Y, Z_train, levels=contour_levels, colors='orange',\n",
    "                               linewidths=1.5, linestyles='dotted')\n",
    "                except Exception as e:\n",
    "                    print(f\"Contour failed for training data at ({i},{j}): {e}\")\n",
    "\n",
    "                # Add contour for model_samples (dashed)\n",
    "                try:\n",
    "                    data_model = np.vstack([data2[:, j], data2[:, i]])\n",
    "                    kde_model = gaussian_kde(data_model)\n",
    "                    Z_model = kde_model(np.vstack([X.ravel(), Y.ravel()])).reshape(X.shape)\n",
    "                    contour_levels_model = get_contour_levels(Z_model, levels=[0.685, 0.955, 0.997])\n",
    "                    ax.contour(X, Y, Z_model, levels=contour_levels_model, colors='purple',\n",
    "                            linewidths=1.2, linestyles='dashed')\n",
    "                except Exception as e:\n",
    "                    print(f\"Contour failed for model data at ({i},{j}): {e}\")\n",
    "\n",
    "            # Labeling\n",
    "            if i == D - 1:\n",
    "                ax.set_xlabel(labels[j], fontsize=14)\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(labels[i], fontsize=14)\n",
    "\n",
    "            #if i < j:\n",
    "            #    ax.axis('off')\n",
    "\n",
    "    # Remove space between subplots\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.subplots_adjust(left=0.07, right=0.95, top=0.95, bottom=0.07)\n",
    "\n",
    "    # Remove ticks and labels for the first and last plots\n",
    "    axes[0, 0].tick_params(axis='both', which='both', bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "    axes[D - 1, D - 1].tick_params(axis='both', which='both', bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "\n",
    "    # Rotate x-axis tick labels\n",
    "    for ax in axes[-1]:\n",
    "        ax.tick_params(axis='x', rotation=45, labelsize=14)\n",
    "\n",
    "    # Rotate y-axis tick labels\n",
    "    for ax in axes[:, 0]:\n",
    "        ax.tick_params(axis='y', rotation=45, labelsize=14)\n",
    "\n",
    "    fig.legend(\n",
    "        labels=density_labels, \n",
    "        loc='center left', \n",
    "        fontsize=12,\n",
    "        frameon=False,\n",
    "        bbox_to_anchor=(0.4, 0.96),\n",
    "        ncol=3\n",
    "    )\n",
    "    if mean_kl is not None:\n",
    "        # annotate mean KL divergence with bbox_to_anchor annotate\n",
    "        fig.text(0.37, 0.955, rf\"$\\langle D_{{KL}} \\rangle = {mean_kl:.3f}$\", \n",
    "                 ha='right', va='bottom', fontsize=12)\n",
    "    if title is not None:\n",
    "        # annotate title with bbox_to_anchor annotate\n",
    "        fig.text(0.15, 0.955, title, \n",
    "                 ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "    plt.savefig(save_path)\n",
    "    plt.close(fig)\n",
    "    del fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_corner_plot(path1, path2, path3, dens_labels, title, filename):\n",
    "    \"\"\"\n",
    "    Wrapper function to read data and create corner plot.\n",
    "    \n",
    "    Parameters:\n",
    "    - path1: path to first data file\n",
    "    - path2: path to second data file\n",
    "    - dens_labels: labels for the density plots\n",
    "    - filename: name of the output file\n",
    "    \"\"\"\n",
    "    data1 = read_pkl_file_chain_pocoMC(path1)\n",
    "    data2 = read_pkl_file_chain_pocoMC(path2)\n",
    "\n",
    "    kl_1d, mean_kl_1d = compute_1d_kl(\n",
    "        p_samples=data1['chain'],\n",
    "        q_samples=data2['chain'],\n",
    "        bounds=bounds,\n",
    "        bins=75\n",
    "    )\n",
    "    kl_2d, mean_kl_2d = compute_2d_kl_lower(\n",
    "        p_samples=data1['chain'],\n",
    "        q_samples=data2['chain'],\n",
    "        bounds=bounds,\n",
    "        bins=75\n",
    "    )\n",
    "    kl_2d_dict = dict(kl_2d)\n",
    "    # Overall mean KL divergence\n",
    "    overall_mean_kl = (mean_kl_1d + mean_kl_2d) / 2.\n",
    "    make_corner_comparison_plot_paper(\n",
    "        data1=data1['chain'],\n",
    "        data2=data2['chain'],\n",
    "        NF_model_path=path3,\n",
    "        bounds=bounds,\n",
    "        labels=param_labels,\n",
    "        density_labels=dens_labels,\n",
    "        bins=75,\n",
    "        save_path=filename,\n",
    "        kl_1d=None,#kl_1d,\n",
    "        kl_2d=None,#kl_2d_dict,\n",
    "        mean_kl=overall_mean_kl,\n",
    "        title=title\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"./mcmc_PCGP_full_vanilla_flat_prior/chain.pkl\"\n",
    "path2 = \"./CLUSTER/start_eP/mcmc_PCGP_eP_prior_vanilla/chain.pkl\"\n",
    "path3 = \"./eP_nf_bs5000_L6_lr1e-03.pkl\"\n",
    "dens_labels = [\"Posterior: joint\", \"Posterior: stage 1\", \"Posterior: stage 2\"]\n",
    "title = r\"Start: $\\gamma+\\mathrm{p}$\"\n",
    "filename = \"./corner_plot_comparison_flat_vs_eP_prior.pdf\"\n",
    "wrapper_corner_plot(path1, path2, path3, dens_labels, title, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
